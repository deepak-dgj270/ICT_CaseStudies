{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Preparation\n",
        "Assuming we have the data in a CSV file with columns text (tweet text) and sentiment (sentiment labels)."
      ],
      "metadata": {
        "id": "gecTgTEYJtol"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xpbtQOWfJrd_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/judge-1377884607_tweet_product_company.csv', encoding='unicode_escape')\n",
        "# Rename columns for easier reference\n",
        "df.rename(columns={'tweet_text': 'text', 'is_there_an_emotion_directed_at_a_brand_or_product': 'sentiment'}, inplace=True)\n",
        "\n",
        "# Ensure all entries in the text column are strings\n",
        "df['text'] = df['text'].astype(str).fillna('')\n",
        "\n",
        "# Preprocess the sentiment labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
        "\n",
        "# Tokenize the tweet texts\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['text'])\n",
        "sequences = tokenizer.texts_to_sequences(df['text'])\n",
        "\n",
        "# Pad the sequences\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "X = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "y = df['sentiment']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: Model Creation\n",
        "We will create an LSTM model. You can switch to a SimpleRNN by replacing the LSTM layer."
      ],
      "metadata": {
        "id": "s2PLvoePKuQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64, input_length=max_length))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dense(4, activation='softmax'))  # 4 classes: positive, negative, neutral, no_idea\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNVP7Z0wKyCX",
        "outputId": "d8330d34-d9fb-47c2-9a88-79ef81c1d7af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 33, 64)            649536    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 682820 (2.60 MB)\n",
            "Trainable params: 682820 (2.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3: Model Training"
      ],
      "metadata": {
        "id": "lz4TixqwK67W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Qr6F0iK7UV",
        "outputId": "5ed11cdb-c77e-4309-af06-50fdea59882d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.1889 - accuracy: 0.9239 - val_loss: 1.4775 - val_accuracy: 0.6454\n",
            "Epoch 2/100\n",
            "182/182 [==============================] - 7s 36ms/step - loss: 0.1772 - accuracy: 0.9249 - val_loss: 1.5685 - val_accuracy: 0.6419\n",
            "Epoch 3/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.1622 - accuracy: 0.9292 - val_loss: 1.4299 - val_accuracy: 0.6392\n",
            "Epoch 4/100\n",
            "182/182 [==============================] - 5s 30ms/step - loss: 0.1554 - accuracy: 0.9313 - val_loss: 1.6521 - val_accuracy: 0.6364\n",
            "Epoch 5/100\n",
            "182/182 [==============================] - 6s 32ms/step - loss: 0.1562 - accuracy: 0.9299 - val_loss: 1.6669 - val_accuracy: 0.6412\n",
            "Epoch 6/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.1415 - accuracy: 0.9383 - val_loss: 1.6781 - val_accuracy: 0.6344\n",
            "Epoch 7/100\n",
            "182/182 [==============================] - 7s 36ms/step - loss: 0.1387 - accuracy: 0.9350 - val_loss: 1.9469 - val_accuracy: 0.6399\n",
            "Epoch 8/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.1445 - accuracy: 0.9385 - val_loss: 1.7897 - val_accuracy: 0.6412\n",
            "Epoch 9/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.1521 - accuracy: 0.9349 - val_loss: 1.7300 - val_accuracy: 0.6344\n",
            "Epoch 10/100\n",
            "182/182 [==============================] - 5s 29ms/step - loss: 0.1377 - accuracy: 0.9378 - val_loss: 1.8423 - val_accuracy: 0.6302\n",
            "Epoch 11/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.1283 - accuracy: 0.9424 - val_loss: 1.9484 - val_accuracy: 0.6316\n",
            "Epoch 12/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.1177 - accuracy: 0.9472 - val_loss: 1.8865 - val_accuracy: 0.6447\n",
            "Epoch 13/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.1339 - accuracy: 0.9459 - val_loss: 1.9793 - val_accuracy: 0.6323\n",
            "Epoch 14/100\n",
            "182/182 [==============================] - 7s 36ms/step - loss: 0.1231 - accuracy: 0.9469 - val_loss: 1.7794 - val_accuracy: 0.6337\n",
            "Epoch 15/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.1123 - accuracy: 0.9500 - val_loss: 2.0180 - val_accuracy: 0.6144\n",
            "Epoch 16/100\n",
            "182/182 [==============================] - 5s 29ms/step - loss: 0.1094 - accuracy: 0.9526 - val_loss: 1.9589 - val_accuracy: 0.6296\n",
            "Epoch 17/100\n",
            "182/182 [==============================] - 6s 34ms/step - loss: 0.1058 - accuracy: 0.9509 - val_loss: 1.8600 - val_accuracy: 0.6378\n",
            "Epoch 18/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.1274 - accuracy: 0.9460 - val_loss: 1.9512 - val_accuracy: 0.6337\n",
            "Epoch 19/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.1120 - accuracy: 0.9503 - val_loss: 2.0098 - val_accuracy: 0.6405\n",
            "Epoch 20/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.1033 - accuracy: 0.9555 - val_loss: 2.0133 - val_accuracy: 0.6433\n",
            "Epoch 21/100\n",
            "182/182 [==============================] - 5s 29ms/step - loss: 0.0873 - accuracy: 0.9608 - val_loss: 2.1070 - val_accuracy: 0.6357\n",
            "Epoch 22/100\n",
            "182/182 [==============================] - 6s 32ms/step - loss: 0.0996 - accuracy: 0.9543 - val_loss: 1.9406 - val_accuracy: 0.6419\n",
            "Epoch 23/100\n",
            "182/182 [==============================] - 5s 26ms/step - loss: 0.0850 - accuracy: 0.9588 - val_loss: 2.0721 - val_accuracy: 0.6344\n",
            "Epoch 24/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.0788 - accuracy: 0.9629 - val_loss: 2.0665 - val_accuracy: 0.6474\n",
            "Epoch 25/100\n",
            "182/182 [==============================] - 5s 26ms/step - loss: 0.0720 - accuracy: 0.9661 - val_loss: 2.2397 - val_accuracy: 0.6426\n",
            "Epoch 26/100\n",
            "182/182 [==============================] - 6s 31ms/step - loss: 0.0753 - accuracy: 0.9643 - val_loss: 2.1846 - val_accuracy: 0.6364\n",
            "Epoch 27/100\n",
            "182/182 [==============================] - 6s 30ms/step - loss: 0.0757 - accuracy: 0.9634 - val_loss: 2.0688 - val_accuracy: 0.6454\n",
            "Epoch 28/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0822 - accuracy: 0.9620 - val_loss: 1.9930 - val_accuracy: 0.6405\n",
            "Epoch 29/100\n",
            "182/182 [==============================] - 6s 36ms/step - loss: 0.1003 - accuracy: 0.9567 - val_loss: 1.8677 - val_accuracy: 0.6440\n",
            "Epoch 30/100\n",
            "182/182 [==============================] - 5s 26ms/step - loss: 0.0862 - accuracy: 0.9608 - val_loss: 2.1978 - val_accuracy: 0.6447\n",
            "Epoch 31/100\n",
            "182/182 [==============================] - 6s 33ms/step - loss: 0.0725 - accuracy: 0.9656 - val_loss: 2.1382 - val_accuracy: 0.6419\n",
            "Epoch 32/100\n",
            "182/182 [==============================] - 5s 30ms/step - loss: 0.0607 - accuracy: 0.9713 - val_loss: 2.4888 - val_accuracy: 0.6412\n",
            "Epoch 33/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.0733 - accuracy: 0.9684 - val_loss: 2.2458 - val_accuracy: 0.6460\n",
            "Epoch 34/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.0697 - accuracy: 0.9682 - val_loss: 2.2741 - val_accuracy: 0.6550\n",
            "Epoch 35/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0747 - accuracy: 0.9649 - val_loss: 2.2439 - val_accuracy: 0.6282\n",
            "Epoch 36/100\n",
            "182/182 [==============================] - 6s 34ms/step - loss: 0.0780 - accuracy: 0.9648 - val_loss: 2.0603 - val_accuracy: 0.6502\n",
            "Epoch 37/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0648 - accuracy: 0.9694 - val_loss: 2.0642 - val_accuracy: 0.6529\n",
            "Epoch 38/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0651 - accuracy: 0.9701 - val_loss: 2.1162 - val_accuracy: 0.6522\n",
            "Epoch 39/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.0590 - accuracy: 0.9723 - val_loss: 2.2996 - val_accuracy: 0.6481\n",
            "Epoch 40/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.0574 - accuracy: 0.9718 - val_loss: 2.2978 - val_accuracy: 0.6495\n",
            "Epoch 41/100\n",
            "182/182 [==============================] - 7s 36ms/step - loss: 0.0597 - accuracy: 0.9739 - val_loss: 2.3211 - val_accuracy: 0.6412\n",
            "Epoch 42/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0599 - accuracy: 0.9732 - val_loss: 1.9009 - val_accuracy: 0.6371\n",
            "Epoch 43/100\n",
            "182/182 [==============================] - 5s 29ms/step - loss: 0.0564 - accuracy: 0.9741 - val_loss: 2.5404 - val_accuracy: 0.6241\n",
            "Epoch 44/100\n",
            "182/182 [==============================] - 6s 34ms/step - loss: 0.0752 - accuracy: 0.9673 - val_loss: 2.2418 - val_accuracy: 0.6440\n",
            "Epoch 45/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.0654 - accuracy: 0.9710 - val_loss: 2.3279 - val_accuracy: 0.6364\n",
            "Epoch 46/100\n",
            "182/182 [==============================] - 6s 34ms/step - loss: 0.0576 - accuracy: 0.9763 - val_loss: 2.2427 - val_accuracy: 0.6454\n",
            "Epoch 47/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0568 - accuracy: 0.9739 - val_loss: 2.3262 - val_accuracy: 0.6302\n",
            "Epoch 48/100\n",
            "182/182 [==============================] - 6s 32ms/step - loss: 0.0496 - accuracy: 0.9783 - val_loss: 2.4076 - val_accuracy: 0.6371\n",
            "Epoch 49/100\n",
            "182/182 [==============================] - 6s 30ms/step - loss: 0.0576 - accuracy: 0.9725 - val_loss: 2.2176 - val_accuracy: 0.6220\n",
            "Epoch 50/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0553 - accuracy: 0.9761 - val_loss: 2.4664 - val_accuracy: 0.6247\n",
            "Epoch 51/100\n",
            "182/182 [==============================] - 7s 36ms/step - loss: 0.0476 - accuracy: 0.9813 - val_loss: 2.4057 - val_accuracy: 0.6275\n",
            "Epoch 52/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.0481 - accuracy: 0.9797 - val_loss: 2.5130 - val_accuracy: 0.6323\n",
            "Epoch 53/100\n",
            "182/182 [==============================] - 7s 36ms/step - loss: 0.0473 - accuracy: 0.9816 - val_loss: 2.6441 - val_accuracy: 0.6309\n",
            "Epoch 54/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0441 - accuracy: 0.9814 - val_loss: 2.6838 - val_accuracy: 0.6474\n",
            "Epoch 55/100\n",
            "182/182 [==============================] - 5s 29ms/step - loss: 0.0477 - accuracy: 0.9806 - val_loss: 2.4764 - val_accuracy: 0.6405\n",
            "Epoch 56/100\n",
            "182/182 [==============================] - 7s 36ms/step - loss: 0.0458 - accuracy: 0.9813 - val_loss: 2.4041 - val_accuracy: 0.6241\n",
            "Epoch 57/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0613 - accuracy: 0.9768 - val_loss: 2.2514 - val_accuracy: 0.6316\n",
            "Epoch 58/100\n",
            "182/182 [==============================] - 6s 36ms/step - loss: 0.0368 - accuracy: 0.9850 - val_loss: 2.6628 - val_accuracy: 0.6440\n",
            "Epoch 59/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0381 - accuracy: 0.9854 - val_loss: 2.5034 - val_accuracy: 0.6371\n",
            "Epoch 60/100\n",
            "182/182 [==============================] - 6s 32ms/step - loss: 0.0360 - accuracy: 0.9849 - val_loss: 2.4963 - val_accuracy: 0.6378\n",
            "Epoch 61/100\n",
            "182/182 [==============================] - 6s 33ms/step - loss: 0.0338 - accuracy: 0.9866 - val_loss: 2.6381 - val_accuracy: 0.6502\n",
            "Epoch 62/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0311 - accuracy: 0.9873 - val_loss: 2.8406 - val_accuracy: 0.6447\n",
            "Epoch 63/100\n",
            "182/182 [==============================] - 6s 36ms/step - loss: 0.0400 - accuracy: 0.9849 - val_loss: 2.0833 - val_accuracy: 0.6433\n",
            "Epoch 64/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0353 - accuracy: 0.9868 - val_loss: 2.5855 - val_accuracy: 0.6488\n",
            "Epoch 65/100\n",
            "182/182 [==============================] - 6s 31ms/step - loss: 0.0334 - accuracy: 0.9859 - val_loss: 2.6558 - val_accuracy: 0.6440\n",
            "Epoch 66/100\n",
            "182/182 [==============================] - 6s 31ms/step - loss: 0.0359 - accuracy: 0.9850 - val_loss: 2.5749 - val_accuracy: 0.6467\n",
            "Epoch 67/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 2.7625 - val_accuracy: 0.6509\n",
            "Epoch 68/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.0395 - accuracy: 0.9857 - val_loss: 2.5539 - val_accuracy: 0.6460\n",
            "Epoch 69/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0324 - accuracy: 0.9866 - val_loss: 2.6135 - val_accuracy: 0.6454\n",
            "Epoch 70/100\n",
            "182/182 [==============================] - 6s 30ms/step - loss: 0.0438 - accuracy: 0.9816 - val_loss: 2.2696 - val_accuracy: 0.6385\n",
            "Epoch 71/100\n",
            "182/182 [==============================] - 6s 33ms/step - loss: 0.0406 - accuracy: 0.9866 - val_loss: 2.2642 - val_accuracy: 0.6323\n",
            "Epoch 72/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0420 - accuracy: 0.9845 - val_loss: 2.1918 - val_accuracy: 0.6460\n",
            "Epoch 73/100\n",
            "182/182 [==============================] - 7s 36ms/step - loss: 0.0389 - accuracy: 0.9854 - val_loss: 2.5559 - val_accuracy: 0.6282\n",
            "Epoch 74/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.0320 - accuracy: 0.9883 - val_loss: 2.4546 - val_accuracy: 0.6378\n",
            "Epoch 75/100\n",
            "182/182 [==============================] - 6s 32ms/step - loss: 0.0288 - accuracy: 0.9893 - val_loss: 2.6498 - val_accuracy: 0.6275\n",
            "Epoch 76/100\n",
            "182/182 [==============================] - 5s 30ms/step - loss: 0.0343 - accuracy: 0.9881 - val_loss: 2.5351 - val_accuracy: 0.6172\n",
            "Epoch 77/100\n",
            "182/182 [==============================] - 5s 27ms/step - loss: 0.0243 - accuracy: 0.9890 - val_loss: 2.7655 - val_accuracy: 0.6316\n",
            "Epoch 78/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.0218 - accuracy: 0.9900 - val_loss: 2.8851 - val_accuracy: 0.6247\n",
            "Epoch 79/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0189 - accuracy: 0.9919 - val_loss: 3.0271 - val_accuracy: 0.6296\n",
            "Epoch 80/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.0214 - accuracy: 0.9912 - val_loss: 2.9325 - val_accuracy: 0.6378\n",
            "Epoch 81/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 2.8865 - val_accuracy: 0.6351\n",
            "Epoch 82/100\n",
            "182/182 [==============================] - 5s 30ms/step - loss: 0.0208 - accuracy: 0.9918 - val_loss: 3.0686 - val_accuracy: 0.6426\n",
            "Epoch 83/100\n",
            "182/182 [==============================] - 6s 34ms/step - loss: 0.0415 - accuracy: 0.9842 - val_loss: 2.5453 - val_accuracy: 0.6247\n",
            "Epoch 84/100\n",
            "182/182 [==============================] - 5s 29ms/step - loss: 0.0357 - accuracy: 0.9875 - val_loss: 2.5955 - val_accuracy: 0.6316\n",
            "Epoch 85/100\n",
            "182/182 [==============================] - 7s 36ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 2.5020 - val_accuracy: 0.6371\n",
            "Epoch 86/100\n",
            "182/182 [==============================] - 5s 29ms/step - loss: 0.0248 - accuracy: 0.9907 - val_loss: 2.6243 - val_accuracy: 0.6357\n",
            "Epoch 87/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 2.7429 - val_accuracy: 0.6337\n",
            "Epoch 88/100\n",
            "182/182 [==============================] - 5s 30ms/step - loss: 0.0198 - accuracy: 0.9918 - val_loss: 2.8284 - val_accuracy: 0.6268\n",
            "Epoch 89/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0217 - accuracy: 0.9911 - val_loss: 2.8119 - val_accuracy: 0.6412\n",
            "Epoch 90/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 2.8956 - val_accuracy: 0.6351\n",
            "Epoch 91/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0159 - accuracy: 0.9928 - val_loss: 2.9756 - val_accuracy: 0.6351\n",
            "Epoch 92/100\n",
            "182/182 [==============================] - 7s 36ms/step - loss: 0.0183 - accuracy: 0.9914 - val_loss: 2.9975 - val_accuracy: 0.6357\n",
            "Epoch 93/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 2.7603 - val_accuracy: 0.6440\n",
            "Epoch 94/100\n",
            "182/182 [==============================] - 5s 29ms/step - loss: 0.0369 - accuracy: 0.9871 - val_loss: 2.2566 - val_accuracy: 0.6529\n",
            "Epoch 95/100\n",
            "182/182 [==============================] - 6s 33ms/step - loss: 0.0328 - accuracy: 0.9883 - val_loss: 2.2472 - val_accuracy: 0.6481\n",
            "Epoch 96/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 2.6151 - val_accuracy: 0.6337\n",
            "Epoch 97/100\n",
            "182/182 [==============================] - 6s 35ms/step - loss: 0.0468 - accuracy: 0.9847 - val_loss: 2.3888 - val_accuracy: 0.6378\n",
            "Epoch 98/100\n",
            "182/182 [==============================] - 5s 28ms/step - loss: 0.0281 - accuracy: 0.9897 - val_loss: 2.2635 - val_accuracy: 0.6440\n",
            "Epoch 99/100\n",
            "182/182 [==============================] - 6s 31ms/step - loss: 0.0405 - accuracy: 0.9847 - val_loss: 2.2662 - val_accuracy: 0.6488\n",
            "Epoch 100/100\n",
            "182/182 [==============================] - 6s 32ms/step - loss: 0.0279 - accuracy: 0.9900 - val_loss: 2.4333 - val_accuracy: 0.6502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4: Model Evaluation"
      ],
      "metadata": {
        "id": "UiIugjb4LBa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZU_QCpWLEnn",
        "outputId": "497bf57d-79c4-4431-e26e-540e79a173d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 1s 14ms/step - loss: 2.6853 - accuracy: 0.6146\n",
            "Test Accuracy: 0.6146234273910522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5: Prediction"
      ],
      "metadata": {
        "id": "AxbnCW8lLHPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict sentiments for new tweets\n",
        "new_tweets = [\"I love my new Apple iPhone!\", \"Google's new update is great.\"]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_tweets)\n",
        "new_padded_sequences = pad_sequences(new_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "predictions = model.predict(new_padded_sequences)\n",
        "predicted_classes = label_encoder.inverse_transform(predictions.argmax(axis=1))\n",
        "\n",
        "for tweet, sentiment in zip(new_tweets, predicted_classes):\n",
        "    print(f'Tweet: {tweet}\\nPredicted Sentiment: {sentiment}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UujgZ9v0LNvN",
        "outputId": "018879ed-c9c0-4989-dc20-d2a070a18b78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "Tweet: I love my new Apple iPhone!\n",
            "Predicted Sentiment: Positive emotion\n",
            "\n",
            "Tweet: Google's new update is great.\n",
            "Predicted Sentiment: Negative emotion\n",
            "\n"
          ]
        }
      ]
    }
  ]
}